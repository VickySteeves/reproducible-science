<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="Promoting reproducibility and openness!">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Reproducible Science (old posts, page 11) | Reproducible Science</title>
<link href="../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://reproduciblescience.org/directory/index-11.html">
<link rel="favicon" href="favicon.ico" sizes="16x16">
<link rel="prev" href="index-10.html" type="text/html">
<link rel="next" href="index-12.html" type="text/html">
<!--[if lt IE 9]><script src="../assets/js/html5.js"></script><![endif]--><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/solid.css" integrity="sha384-TbilV5Lbhlwdyc4RuIV/JhD8NR+BfMrvz4BL5QFa2we1hQu6wvREr3v6XSRfCTRp" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/regular.css" integrity="sha384-avJt9MoJH2rB4PKRsJRHZv7yiFZn8LrnXuzvmZoD3fh1aL6aM6s0BBcnCvBe6XSD" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/brands.css" integrity="sha384-7xAnn7Zm3QC1jFjVc1A6v/toepoG3JXboQYzbM0jrPzou9OFXm/fY6Z/XiIebl/k" crossorigin="anonymous">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/fontawesome.css" integrity="sha384-ozJwkrqb90Oa3ZNb+yKFW2lToAWYdTiF1vt8JiH5ptTGHTGcN7qdoR1F95e0kYyG" crossorigin="anonymous">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-lg navbar-dark bg-primary static-top mb-4"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://reproduciblescience.org/">
            <img src="../logo.png" alt="Reproducible Science" id="logo" class="d-inline-block align-top"><span id="blog-title">Reproducible Science</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="navbar-nav mr-auto">
<li class="nav-item">
<a href="../who-we-are/" class="nav-link">Who We Are</a>
         </li>
<li class="nav-item">
<a href="../contribute/" class="nav-link">Contribute</a>
         </li>
<li class="nav-item">
<a href="." class="nav-link">Reproducible Resource Directory</a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right">
<li class="nav-item">
<a href="https://github.com/vida-nyu/reproducible-science" class="nav-link"><i class="fab fa-github"></i></a>
         </li>
<li class="nav-item">
<a href="https://twitter.com/ReproFeed" class="nav-link"><i class="fab fa-twitter"></i></a>
         </li>
<li class="nav-item">
<a href="https://vida-nyu.github.io/reproducibility-news/feed.rss" class="nav-link"><i class="fas fa-rss"></i></a>

                
                
                
            </li>
</ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        
        

    


    

    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="https://arxiv.org/abs/1809.10139" class="u-url">Predicting computational reproducibility of data analysis pipelines in large population studies using collaborative filtering</a></h1>
        <div class="metadata">
            <p class="dateline"><time class="published dt-published" datetime="2018-10-03T00:00:00-04:00" title="03-10-2018">03-10-2018</time></p>  
						<p><a href="mailto:?subject=I%20saw%20this%20and%20thought%20of%20you!&amp;body=Predicting%20computational%20reproducibility%20of%20data%20analysis%20pipelines%20in%20large%20population%20studies%20using%20collaborative%20filtering;%20https://arxiv.org/abs/1809.10139" onclick="ga('send', 'social', 'email', 'share', https://arxiv.org/abs/1809.10139); return true;">Email this article</a></p>
						<p><a href="https://twitter.com/share?url=/directory/directory/Predicting-computational-reproducibility-of-data-analysis-pi/);text=Predicting%20computational%20reproducibility%20of%20data%20analysis%20pipelines%20in%20large%20population%20studies%20using%20collaborative%20filtering,%20https://arxiv.org/abs/1809.10139" onclick="ga('send', 'social', 'Twitter', 'tweet', /directory/directory/Predicting-computational-reproducibility-of-data-analysis-pi/); return true;" target="_blank">Tweet this article</a></p> 
        </div>
    </header><div class="e-content entry-content">
    <p>Evaluating the computational reproducibility of data analysis pipelines has become a critical issue. It is, however, a cumbersome process for analyses that involve data from large populations of subjects, due to their computational and storage requirements. We present a method to predict the computational reproducibility of data analysis pipelines in large population studies. We formulate the problem as a collaborative filtering process, with constraints on the construction of the training set. We propose 6 different strategies to build the training set, which we evaluate on 2 datasets, a synthetic one modeling a population with a growing number of subject types, and a real one obtained with neuroinformatics pipelines. Results show that one sampling method, "Random File Numbers (Uniform)" is able to predict computational reproducibility with a good accuracy. We also analyze the relevance of including file and subject biases in the collaborative filtering model. We conclude that the proposed method is able to speedup reproducibility evaluations substantially, with a reduced accuracy loss.</p>
		<div id="index-tags">
		  <ul class="tags">
			Tagged:
		  	<li class="tag"><a href="../categories/reproducible-paper/">reproducible paper</a></li>          
		  </ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="https://arxiv.org/abs/1809.07693v1" class="u-url">A Serverless Tool for Platform Agnostic Computational Experiment Management</a></h1>
        <div class="metadata">
            <p class="dateline"><time class="published dt-published" datetime="2018-09-25T00:00:00-04:00" title="25-09-2018">25-09-2018</time></p>  
						<p><a href="mailto:?subject=I%20saw%20this%20and%20thought%20of%20you!&amp;body=A%20Serverless%20Tool%20for%20Platform%20Agnostic%20Computational%20Experiment%20Management;%20https://arxiv.org/abs/1809.07693v1" onclick="ga('send', 'social', 'email', 'share', https://arxiv.org/abs/1809.07693v1); return true;">Email this article</a></p>
						<p><a href="https://twitter.com/share?url=/directory/directory/A-Serverless-Tool-for-Platform-Agnostic-Computational-Experi/);text=A%20Serverless%20Tool%20for%20Platform%20Agnostic%20Computational%20Experiment%20Management,%20https://arxiv.org/abs/1809.07693v1" onclick="ga('send', 'social', 'Twitter', 'tweet', /directory/directory/A-Serverless-Tool-for-Platform-Agnostic-Computational-Experi/); return true;" target="_blank">Tweet this article</a></p> 
        </div>
    </header><div class="e-content entry-content">
    <p>Neuroscience has been carried into the domain of big data and high performance computing (HPC) on the backs of initiatives in data collection and an increasingly compute-intensive tools. While managing HPC experiments requires considerable technical acumen, platforms and standards have been developed to ease this burden on scientists. While web-portals make resources widely accessible, data organizations such as the Brain Imaging Data Structure and tool description languages such as Boutiques provide researchers with a foothold to tackle these problems using their own datasets, pipelines, and environments. While these standards lower the barrier to adoption of HPC and cloud systems for neuroscience applications, they still require the consolidation of disparate domain-specific knowledge. We present Clowdr, a lightweight tool to launch experiments on HPC systems and clouds, record rich execution records, and enable the accessible sharing of experimental summaries and results. Clowdr uniquely sits between web platforms and bare-metal applications for experiment management by preserving the flexibility of do-it-yourself solutions while providing a low barrier for developing, deploying and disseminating neuroscientific analysis.</p>
		<div id="index-tags">
		  <ul class="tags">
			Tagged:
		  	<li class="tag"><a href="../categories/reproducibility-infrastructure/">reproducibility infrastructure</a></li>          
		  	<li class="tag"><a href="../categories/reproducible-paper/">reproducible paper</a></li>          
		  </ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="https://openaccess.leidenuniv.nl/bitstream/handle/1887/65315/STI2018_paper_113.pdf?sequence=1" class="u-url">Exploration of reproducibility issues in scientometric research</a></h1>
        <div class="metadata">
            <p class="dateline"><time class="published dt-published" datetime="2018-09-21T00:00:00-04:00" title="21-09-2018">21-09-2018</time></p>  
						<p><a href="mailto:?subject=I%20saw%20this%20and%20thought%20of%20you!&amp;body=Exploration%20of%20reproducibility%20issues%20in%20scientometric%20research;%20https://openaccess.leidenuniv.nl/bitstream/handle/1887/65315/STI2018_paper_113.pdf?sequence=1" onclick="ga('send', 'social', 'email', 'share', https://openaccess.leidenuniv.nl/bitstream/handle/1887/65315/STI2018_paper_113.pdf?sequence=1); return true;">Email this article</a></p>
						<p><a href="https://twitter.com/share?url=/directory/directory/Exploration-of-reproducibility-issues-in-scientometric-resea/);text=Exploration%20of%20reproducibility%20issues%20in%20scientometric%20research,%20https://openaccess.leidenuniv.nl/bitstream/handle/1887/65315/STI2018_paper_113.pdf?sequence=1" onclick="ga('send', 'social', 'Twitter', 'tweet', /directory/directory/Exploration-of-reproducibility-issues-in-scientometric-resea/); return true;" target="_blank">Tweet this article</a></p> 
        </div>
    </header><div class="e-content entry-content">
    <p>In scientometrics, we have not yet had an intensive debate about the reproducibility of research published in our field, although concerns about  a  lack  of  reproducibility  have occasionally surfaced (see e.g. Glänzel &amp; Schöpflin 1994 and Van den Besselaar et al. 2017), and the need to improve the reproducibility is used as an important argument for open citation data  (see www.issi-society.org/open-citations-letter/).  We  initiated  a  first  discussion  about reproducibility  in  scientometrics  with  a  workshop  at  ISSI  2017  in  Wuhan. One of the outcomes was the sense that scientific fields differ with regard to the type and pervasiveness of  threats to the reproducibility  of  their  published  research,  last  but  not  least  due  to  their differences in modes of knowledge production, such as confirmatory versus exploratory study designs, and differences in methods and empirical objects.</p>
		<div id="index-tags">
		  <ul class="tags">
			Tagged:
		  	<li class="tag"><a href="../categories/reproducible-paper/">reproducible paper</a></li>          
		  </ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="https://psyarxiv.com/cnq4d/" class="u-url">Reproducibility and Replicability in a Fast-paced Methodological World</a></h1>
        <div class="metadata">
            <p class="dateline"><time class="published dt-published" datetime="2018-09-21T00:00:00-04:00" title="21-09-2018">21-09-2018</time></p>  
						<p><a href="mailto:?subject=I%20saw%20this%20and%20thought%20of%20you!&amp;body=Reproducibility%20and%20Replicability%20in%20a%20Fast-paced%20Methodological%20World;%20https://psyarxiv.com/cnq4d/" onclick="ga('send', 'social', 'email', 'share', https://psyarxiv.com/cnq4d/); return true;">Email this article</a></p>
						<p><a href="https://twitter.com/share?url=/directory/directory/Reproducibility-and-Replicability-in-a-Fast-paced-Methodolog/);text=Reproducibility%20and%20Replicability%20in%20a%20Fast-paced%20Methodological%20World,%20https://psyarxiv.com/cnq4d/" onclick="ga('send', 'social', 'Twitter', 'tweet', /directory/directory/Reproducibility-and-Replicability-in-a-Fast-paced-Methodolog/); return true;" target="_blank">Tweet this article</a></p> 
        </div>
    </header><div class="e-content entry-content">
    <p>Methodological developments and software implementations progress in increasingly faster time-frames. The introduction and widespread acceptance of pre-print archived reports and open-source software make state-of-the-art statistical methods readily accessible to researchers. At the same time, researchers more and more emphasize that their results should be reproducible (using the same data obtaining the same results), which is a basic requirement for assessing the replicability (obtaining similar results in new data) of results. While the age of fast-paced methodology greatly facilitates reproducibility, it also undermines it in ways not often realized by researchers. The goal of this paper is to make researchers aware of these caveats. I discuss sources of limited replicability and reproducibility in both the development of novel statistical methods and their implementation in software routines. Novel methodology comes with many researcher degrees of freedom, and new understanding comes with changing standards over time.  In software-development, reproducibility may be impacted due to software developing and changing over time, a problem that is greatly magnified by large dependency-trees between software-packages. The paper concludes with a list of recommendations for both developers and users of new methods to improve reproducibility of results.</p>
		<div id="index-tags">
		  <ul class="tags">
			Tagged:
		  	<li class="tag"><a href="../categories/reproducible-paper/">reproducible paper</a></li>          
		  </ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="https://link.springer.com/chapter/10.1007/978-3-319-98379-0_3" class="u-url">Classification of Provenance Triples for Scientific Reproducibility: A Comparative Evaluation of Deep Learning Models in the ProvCaRe Project</a></h1>
        <div class="metadata">
            <p class="dateline"><time class="published dt-published" datetime="2018-09-11T00:00:00-04:00" title="11-09-2018">11-09-2018</time></p>  
						<p><a href="mailto:?subject=I%20saw%20this%20and%20thought%20of%20you!&amp;body=Classification%20of%20Provenance%20Triples%20for%20Scientific%20Reproducibility:%20A%20Comparative%20Evaluation%20of%20Deep%20Learning%20Models%20in%20the%20ProvCaRe%20Project;%20https://link.springer.com/chapter/10.1007/978-3-319-98379-0_3" onclick="ga('send', 'social', 'email', 'share', https://link.springer.com/chapter/10.1007/978-3-319-98379-0_3); return true;">Email this article</a></p>
						<p><a href="https://twitter.com/share?url=/directory/directory/Classification-of-Provenance-Triples-for-Scientific-Reproduc/);text=Classification%20of%20Provenance%20Triples%20for%20Scientific%20Reproducibility:%20A%20Comparative%20Evaluation%20of%20Deep%20Learning%20Models%20in%20the%20ProvCaRe%20Project,%20https://link.springer.com/chapter/10.1007/978-3-319-98379-0_3" onclick="ga('send', 'social', 'Twitter', 'tweet', /directory/directory/Classification-of-Provenance-Triples-for-Scientific-Reproduc/); return true;" target="_blank">Tweet this article</a></p> 
        </div>
    </header><div class="e-content entry-content">
    <p>Scientific reproducibility is key to the advancement of science as researchers can build on sound and validated results to design new research studies. However, recent studies in biomedical research have highlighted key challenges in scientific reproducibility as more than 70% of researchers in a survey of more than 1500 participants were not able to reproduce results from other groups and 50% of researchers were not able to reproduce their own experiments. Provenance metadata is a key component of scientific reproducibility and as part of the Provenance for Clinical and Health Research (ProvCaRe) project, we have: (1) identified and modeled important provenance terms associated with a biomedical research study in the S3 model (formalized in the ProvCaRe ontology); (2) developed a new natural language processing (NLP) workflow to identify and extract provenance metadata from published articles describing biomedical research studies; and (3) developed the ProvCaRe knowledge repository to enable users to query and explore provenance of research studies using the S3 model. However, a key challenge in this project is the automated classification of provenance metadata extracted by the NLP workflow according to the S3 model and its subsequent querying in the ProvCaRe knowledge repository. In this paper, we describe the development and comparative evaluation of deep learning techniques for multi-class classification of structured provenance metadata extracted from biomedical literature using 12 different categories of provenance terms represented in the S3 model. We describe the application of the Long Term Short Memory (LSTM) network, which has the highest classification accuracy of 86% in our evaluation, to classify more than 48 million provenance triples in the ProvCaRe knowledge repository (available at: https://provcare.case.edu/).</p>
		<div id="index-tags">
		  <ul class="tags">
			Tagged:
		  	<li class="tag"><a href="../categories/reproducibility-infrastructure/">reproducibility infrastructure</a></li>          
		  	<li class="tag"><a href="../categories/reproducible-paper/">reproducible paper</a></li>          
		  </ul>
</div>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="https://link.springer.com/article/10.1007/s11538-018-0496-1" class="u-url">Issues in Reproducible Simulation Research</a></h1>
        <div class="metadata">
            <p class="dateline"><time class="published dt-published" datetime="2018-09-11T00:00:00-04:00" title="11-09-2018">11-09-2018</time></p>  
						<p><a href="mailto:?subject=I%20saw%20this%20and%20thought%20of%20you!&amp;body=Issues%20in%20Reproducible%20Simulation%20Research;%20https://link.springer.com/article/10.1007/s11538-018-0496-1" onclick="ga('send', 'social', 'email', 'share', https://link.springer.com/article/10.1007/s11538-018-0496-1); return true;">Email this article</a></p>
						<p><a href="https://twitter.com/share?url=/directory/directory/Issues-in-Reproducible-Simulation-Research/);text=Issues%20in%20Reproducible%20Simulation%20Research,%20https://link.springer.com/article/10.1007/s11538-018-0496-1" onclick="ga('send', 'social', 'Twitter', 'tweet', /directory/directory/Issues-in-Reproducible-Simulation-Research/); return true;" target="_blank">Tweet this article</a></p> 
        </div>
    </header><div class="e-content entry-content">
    <p>In recent years, serious concerns have arisen about reproducibility in science. Estimates of the cost of irreproducible preclinical studies range from 28 billion USD per year in the USA alone (Freedman et al. in PLoS Biol 13(6):e1002165, 2015) to over 200 billion USD per year worldwide (Chalmers and Glasziou in Lancet 374:86–89, 2009). The situation in the social sciences is not very different: Reproducibility in psychological research, for example, has been estimated to be below 50% as well (Open Science Collaboration in Science 349:6251, 2015). Less well studied is the issue of reproducibility of simulation research. A few replication studies of agent-based models, however, suggest the problem for computational modeling may be more severe than for laboratory experiments (Willensky and Rand in JASSS 10(4):2, 2007; Donkin et al. in Environ Model Softw 92:142–151, 2017; Bajracharya and Duboz in: Proceedings of the symposium on theory of modeling and simulation—DEVS integrative M&amp;S symposium, pp 6–11, 2013). In this perspective, we discuss problems of reproducibility in agent-based simulations of life and social science problems, drawing on best practices research in computer science and in wet-lab experiment design and execution to suggest some ways to improve simulation research practice.</p>
		<div id="index-tags">
		  <ul class="tags">
			Tagged:
		  	<li class="tag"><a href="../categories/reproducible-paper/">reproducible paper</a></li>          
		  </ul>
</div>
    </div>
    </article><nav aria-label="Page navigation"><ul class="pagination pagination-lg justify-content-center">
<li class="page-item"><a href="index-10.html" class="page-link" aria-label="Newer posts"><span aria-hidden="true">«</span></a></li>
      <li class="page-item "><a href="." class="page-link">1</a></li>
      <li class="page-item disabled"><a href="#" class="page-link" aria-label="…"><span aria-hidden="true">…</span></a></li>
      <li class="page-item "><a href="index-6.html" class="page-link">7</a></li>
      <li class="page-item "><a href="index-7.html" class="page-link">8</a></li>
      <li class="page-item "><a href="index-8.html" class="page-link">9</a></li>
      <li class="page-item "><a href="index-9.html" class="page-link">10</a></li>
      <li class="page-item "><a href="index-10.html" class="page-link">11</a></li>
      <li class="page-item active"><a href="#" class="page-link">12 <span class="sr-only">(current)</span></a></li>
      <li class="page-item "><a href="index-12.html" class="page-link">13</a></li>
      <li class="page-item "><a href="index-13.html" class="page-link">14</a></li>
      <li class="page-item "><a href="index-14.html" class="page-link">15</a></li>
      <li class="page-item "><a href="index-15.html" class="page-link">16</a></li>
      <li class="page-item "><a href="index-16.html" class="page-link">17</a></li>
      <li class="page-item disabled"><a href="#" class="page-link" aria-label="…"><span aria-hidden="true">…</span></a></li>
      <li class="page-item "><a href="index-78.html" class="page-link">79</a></li>
      <li class="page-item"><a href="index-12.html" class="page-link" aria-label="Older posts"><span aria-hidden="true">»</span></a></li>
  </ul></nav><!--End of body content--><footer id="footer" class="mt-4 mb-4">
            2019 <a href="mailto:vicky.steeves@nyu.edu">NYU Reproducibility WG</a> | <a href="https://github.com/vida-nyu/reproducible-science"><i class="fab fa-github"></i></a> <a href="https://twitter.com/ReproFeed"><i class="fab fa-twitter"></i></a> <a href="https://vida-nyu.github.io/reproducibility-news/feed.rss"><i class="fas fa-rss"></i></a>
            
        </footer>
</div>
</div>


        <script src="../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "DD:MM:YYYY");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-86255717-1', 'auto');
ga('send', 'pageview');</script>
</body>
</html>
